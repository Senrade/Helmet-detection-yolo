{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torchvision\n",
    "import gc\n",
    "import roboflow\n",
    "from roboflow import Roboflow\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA AND TORCH CHECKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "tensor = torch.rand(3,3).cuda()\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "boxes = torch.tensor([[0, 0, 1, 1], [0.9, 0.9, 2, 2]], dtype=torch.float32).cuda()\n",
    "scores = torch.tensor([0.9, 0.8], dtype=torch.float32).cuda()\n",
    "\n",
    "# Perform NMS\n",
    "nms_indices = torchvision.ops.nms(boxes, scores, iou_threshold=0.5)\n",
    "nms_indices = nms_indices.cuda()\n",
    "print(f\"NMS indices: {nms_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.version.cuda\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    model = YOLO(r'D:\\Projects\\Helmet detection\\Model\\yolov8m-seg.pt')\n",
    "\n",
    "    model.train(data=r'D:\\Projects\\Helmet detection\\Data\\data.yaml', epochs=50, imgsz=480, batch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(r'')\n",
    "res=model(source=r'D:\\Projects\\Helmet detection\\Data\\test',save=False,conf=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"AlBM3nHUZMJlOEAokjuW\")\n",
    "project = rf.workspace().project(\"helmet-and-nonhelmet-detection\")\n",
    "model = project.version(1).model\n",
    "\n",
    "# Predict using the model\n",
    "result = model.predict(r\"D:\\Projects\\Helmet detection\\Data\\train\\images\\_tmp_44d613c041772528ae5b2f76238cb3844827view_jpg.rf.c0c647c91e6740db45b8eceaa2a20fb7.jpg\", confidence=90, overlap=10,labels=True)\n",
    "predictions = result[0]['confidence']\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Frame processed in 6.39 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.02 seconds.\n",
      "Frame processed in 2.24 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.02 seconds.\n",
      "Frame processed in 0.06 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 4.26 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.04 seconds.\n",
      "Frame processed in 3.51 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 1.03 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 2.58 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.02 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.02 seconds.\n",
      "Frame processed in 0.94 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.04 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 1.08 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.03 seconds.\n",
      "Frame processed in 0.01 seconds.\n",
      "Frame processed in 0.03 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m pil_image\u001b[38;5;241m.\u001b[39msave(temp_image_path)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Motorcycle detection\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m result_motorcycle \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_motorcycle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m predictions_motorcycle \u001b[38;5;241m=\u001b[39m result_motorcycle\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m motorcycle \u001b[38;5;129;01min\u001b[39;00m predictions_motorcycle:\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\roboflow\\models\\object_detection.py:207\u001b[0m, in \u001b[0;36mObjectDetectionModel.predict\u001b[1;34m(self, image_path, hosted, format, classes, overlap, confidence, stroke, labels)\u001b[0m\n\u001b[0;32m    205\u001b[0m     img_str \u001b[38;5;241m=\u001b[39m img_str\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m# Post to API and return response\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/x-www-form-urlencoded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     image_dims \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(original_dimensions[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(original_dimensions[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m    216\u001b[0m     }\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_path, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# Performing inference on a OpenCV2 frame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:414\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%x\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(chunk), chunk))\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Regardless of whether we have a body or not, if we're in\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# chunked mode we want to send an explicit empty chunk.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunked:\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1036\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.send\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, data)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable):\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1212\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1210\u001b[0m         amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(byte_view)\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m count \u001b[38;5;241m<\u001b[39m amount:\n\u001b[1;32m-> 1212\u001b[0m             v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m             count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1181\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1180\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(data, flags)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Function to generate unique filenames for temporary images\n",
    "def get_unique_filename(file_path):\n",
    "    base, extension = os.path.splitext(file_path)\n",
    "    counter = 1\n",
    "    new_file_path = file_path\n",
    "    while os.path.exists(new_file_path):\n",
    "        new_file_path = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "    return new_file_path\n",
    "\n",
    "# Pre-load models once outside the loop\n",
    "rf_motorcycle = Roboflow(api_key=\"lNRNQAqP9F0FHx3Bokha\")\n",
    "project_motorcycle = rf_motorcycle.workspace(\"vens-shell\").project(\"motorcycle-detection-ctu3w\")\n",
    "model_motorcycle = project_motorcycle.version(2).model\n",
    "\n",
    "rf_helmet = Roboflow(api_key=\"AlBM3nHUZMJlOEAokjuW\")\n",
    "project_helmet = rf_helmet.workspace().project(\"helmet-and-nonhelmet-detection\")\n",
    "model_helmet = project_helmet.version(1).model\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default webcam\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 5  # Detect only every 5th frame to speed up the process\n",
    "\n",
    "# Main loop for real-time detection\n",
    "while True:\n",
    "    start_time = time.time()  # Measure processing time per frame\n",
    "    ret, frame = cap.read()  # Capture a frame from the webcam\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB format\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(frame_rgb)\n",
    "\n",
    "    if frame_count % skip_frames == 0:  # Only detect every 'skip_frames' frames\n",
    "        # Save the current frame as a temporary image\n",
    "        temp_image_path = get_unique_filename(r\"D:\\Projects\\Helmet detection\\Predict\\Temp_frame\\temp_frame.jpg\")\n",
    "        pil_image.save(temp_image_path)\n",
    "\n",
    "        # Motorcycle detection\n",
    "        result_motorcycle = model_motorcycle.predict(temp_image_path, confidence=50, overlap=10)\n",
    "        predictions_motorcycle = result_motorcycle.predictions\n",
    "\n",
    "        for motorcycle in predictions_motorcycle:\n",
    "            moto_bbox = motorcycle['x'], motorcycle['y'], motorcycle['width'], motorcycle['height']\n",
    "            moto_x0, moto_y0 = moto_bbox[0] - moto_bbox[2] / 2, moto_bbox[1] - moto_bbox[3] / 2\n",
    "            moto_x1, moto_y1 = moto_bbox[0] + moto_bbox[2] / 2, moto_bbox[1] + moto_bbox[3] / 2\n",
    "\n",
    "            # Crop motorcycle region for helmet detection\n",
    "            motorcycle_image = pil_image.crop((moto_x0, moto_y0, moto_x1, moto_y1))\n",
    "            temp_motorcycle_path = get_unique_filename(r\"D:\\Projects\\Helmet detection\\Predict\\Temp_frame\\temp_motorcycle.jpg\")\n",
    "            motorcycle_image.save(temp_motorcycle_path)\n",
    "\n",
    "            # Helmet detection in cropped region\n",
    "            result_helmet = model_helmet.predict(temp_motorcycle_path, confidence=70, overlap=10, labels=True)\n",
    "            predictions_helmet = result_helmet.predictions\n",
    "\n",
    "            # Draw bounding boxes for helmets and non-helmets\n",
    "            for prediction in predictions_helmet:\n",
    "                bbox = prediction['x'] + moto_x0, prediction['y'] + moto_y0, prediction['width'], prediction['height']\n",
    "                x0, y0 = bbox[0] - bbox[2] / 2, bbox[1] - bbox[3] / 2\n",
    "                x1, y1 = bbox[0] + bbox[2] / 2, bbox[1] + bbox[3] / 2\n",
    "\n",
    "                label = f\"({prediction['confidence']*100:.2f}%)\"\n",
    "                color = \"green\" if prediction['class'] == \"Helmet\" else \"red\"\n",
    "\n",
    "                # Draw the rectangle and label for helmet/non-helmet\n",
    "                draw = ImageDraw.Draw(pil_image)\n",
    "                draw.rectangle([x0, y0, x1, y1], outline=color, width=2)\n",
    "                draw.rectangle((x0, y0 - 20, x0 + len(label)*14, y0), fill=color)\n",
    "                draw.text((x0, y0 - 20), label, fill=\"black\", font=ImageFont.load_default())\n",
    "\n",
    "            os.remove(temp_motorcycle_path)  # Clean up temporary cropped motorcycle image\n",
    "        os.remove(temp_image_path)  # Clean up temporary frame image\n",
    "\n",
    "    # Convert back to OpenCV format and display the frame\n",
    "    frame_bgr = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    display_width = 1280\n",
    "    aspect_ratio = frame_bgr.shape[1] / frame_bgr.shape[0]\n",
    "    display_height = int(display_width / aspect_ratio)\n",
    "    resized_frame = cv2.resize(frame_bgr, (display_width, display_height))\n",
    "    # cv2.imshow('Helmet Detection', frame_bgr)\n",
    "\n",
    "    print(f\"Frame processed in {time.time() - start_time:.2f} seconds.\")  # Measure time per frame\n",
    "\n",
    "    # Increment frame count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def get_unique_filename(file_path):\n",
    "    base, extension = os.path.splitext(file_path)\n",
    "    counter = 1\n",
    "    new_file_path = file_path\n",
    "    while os.path.exists(new_file_path):\n",
    "        new_file_path = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "    return new_file_path\n",
    "\n",
    "# Kết nối với model motorcycle\n",
    "rf_motorcycle = Roboflow(api_key=\"lNRNQAqP9F0FHx3Bokha\")\n",
    "project_motorcycle = rf_motorcycle.workspace(\"vens-shell\").project(\"motorcycle-detection-ctu3w\")\n",
    "model_motorcycle = project_motorcycle.version(2).model\n",
    "\n",
    "# Kết nối với model helmet\n",
    "rf_helmet = Roboflow(api_key=\"AlBM3nHUZMJlOEAokjuW\")\n",
    "project_helmet = rf_helmet.workspace().project(\"helmet-and-nonhelmet-detection\")\n",
    "model_helmet = project_helmet.version(1).model\n",
    "\n",
    "# Dự đoán xe máy sử dụng mô hình\n",
    "result_motorcycle = model_motorcycle.predict(r\"D:\\Projects\\Helmet detection\\Sample\\Image\\sample3.jpg\", confidence=50, overlap=10)\n",
    "predictions_motorcycle = result_motorcycle.predictions\n",
    "\n",
    "# Mở hình ảnh\n",
    "image_path = r\"D:\\Projects\\Helmet detection\\Sample\\Image\\sample3.jpg\"\n",
    "image = Image.open(image_path)\n",
    "image_width, image_height = image.size\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Dynamically set bounding box thickness and font size based on image size\n",
    "box_thickness = max(1, int(min(image_width, image_height) * 0.005))  # Scale thickness by 0.5% of the smaller dimension\n",
    "font_size = max(10, int(min(image_width, image_height) * 0.006))  # Scale font size by 3% of the smaller dimension\n",
    "\n",
    "# Font để hiển thị nhãn (tùy chọn)\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "# Vẽ các hộp dự đoán lên ảnh\n",
    "for motorcycle in predictions_motorcycle:\n",
    "    moto_bbox = motorcycle['x'], motorcycle['y'], motorcycle['width'], motorcycle['height']\n",
    "    moto_x0, moto_y0 = moto_bbox[0] - moto_bbox[2] / 2, moto_bbox[1] - moto_bbox[3] / 2\n",
    "    moto_x1, moto_y1 = moto_bbox[0] + moto_bbox[2] / 2, moto_bbox[1] + moto_bbox[3] / 2\n",
    "\n",
    "    motorcycle_image = image.crop((moto_x0, moto_y0, moto_x1, moto_y1))  # Cắt vùng ưu tiên và lưu tạm thời\n",
    "    temp_image_path = get_unique_filename(r\"D:\\Projects\\Helmet detection\\Predict\\Temp_frame\\temp_motorcycle.jpg\")\n",
    "    motorcycle_image.save(temp_image_path)\n",
    "\n",
    "    # Dự đoán helmet trong vùng ưu tiên\n",
    "    result_helmet = model_helmet.predict(temp_image_path, confidence=70, overlap=10, labels=True)\n",
    "    predictions_helmet = result_helmet.predictions\n",
    "    \n",
    "    # Vẽ bounding box và label cho mũ bảo hiểm\n",
    "    for prediction in predictions_helmet:\n",
    "        bbox = prediction['x'] + moto_x0, prediction['y'] + moto_y0, prediction['width'], prediction['height']\n",
    "        x0, y0 = bbox[0] - bbox[2] / 2, bbox[1] - bbox[3] / 2\n",
    "        x1, y1 = bbox[0] + bbox[2] / 2, bbox[1] + bbox[3] / 2\n",
    "        \n",
    "        label = f\"({prediction['confidence']*100:.2f}%)\"\n",
    "        \n",
    "        # Use textbbox to get the bounding box size of the text\n",
    "        label_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "        label_width = label_bbox[2] - label_bbox[0] + 10  # Add padding around text\n",
    "        label_height = label_bbox[3] - label_bbox[1] + 5  # Label height based on font size with some padding\n",
    "        \n",
    "        if prediction['class'] == \"Helmet\":\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=\"green\", width=box_thickness)\n",
    "            draw.rectangle((x0, y0 - label_height, x0 + label_width, y0), fill=\"green\")\n",
    "            draw.text((x0 + 5, y0 - label_height), label, fill=\"black\", font=font)\n",
    "        elif prediction['class'] == \"Nonhelmet\":\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=box_thickness)\n",
    "            draw.rectangle((x0, y0 - label_height, x0 + label_width, y0), fill=\"red\")\n",
    "            draw.text((x0 + 5, y0 - label_height), label, fill=\"black\", font=font)\n",
    "    \n",
    "    os.remove(temp_image_path)\n",
    "\n",
    "# Hiển thị ảnh đã dự đoán\n",
    "plt.figure(figsize=(20, 20))  # Increase figure size to make the window larger\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Tắt trục\n",
    "plt.show()\n",
    "\n",
    "# Lưu ảnh đã chú thích nếu cần\n",
    "path = get_unique_filename(r\"D:\\Projects\\Helmet detection\\Predict\\Image\\predict.jpg\")\n",
    "image.save(path)\n",
    "\n",
    "print(\"Execution time: %.2f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Processed frame 1 / 294\n",
      "Processed frame 2 / 294\n",
      "Processed frame 3 / 294\n",
      "Processed frame 4 / 294\n",
      "Processed frame 5 / 294\n",
      "Processed frame 6 / 294\n",
      "Processed frame 7 / 294\n",
      "Processed frame 8 / 294\n",
      "Processed frame 9 / 294\n",
      "Processed frame 10 / 294\n",
      "Processed frame 11 / 294\n",
      "Processed frame 12 / 294\n",
      "Processed frame 13 / 294\n",
      "Processed frame 14 / 294\n",
      "Processed frame 15 / 294\n",
      "Processed frame 16 / 294\n",
      "Processed frame 17 / 294\n",
      "Processed frame 18 / 294\n",
      "Processed frame 19 / 294\n",
      "Processed frame 20 / 294\n",
      "Processed frame 21 / 294\n",
      "Processed frame 22 / 294\n",
      "Processed frame 23 / 294\n",
      "Processed frame 24 / 294\n",
      "Processed frame 25 / 294\n",
      "Processed frame 26 / 294\n",
      "Processed frame 27 / 294\n",
      "Processed frame 28 / 294\n",
      "Processed frame 29 / 294\n",
      "Processed frame 30 / 294\n",
      "Processed frame 31 / 294\n",
      "Processed frame 32 / 294\n",
      "Processed frame 33 / 294\n",
      "Processed frame 34 / 294\n",
      "Processed frame 35 / 294\n",
      "Processed frame 36 / 294\n",
      "Processed frame 37 / 294\n",
      "Processed frame 38 / 294\n",
      "Processed frame 39 / 294\n",
      "Processed frame 40 / 294\n",
      "Processed frame 41 / 294\n",
      "Processed frame 42 / 294\n",
      "Processed frame 43 / 294\n",
      "Processed frame 44 / 294\n",
      "Processed frame 45 / 294\n",
      "Processed frame 46 / 294\n",
      "Processed frame 47 / 294\n",
      "Processed frame 48 / 294\n",
      "Processed frame 49 / 294\n",
      "Processed frame 50 / 294\n",
      "Processed frame 51 / 294\n",
      "Processed frame 52 / 294\n",
      "Processed frame 53 / 294\n",
      "Processed frame 54 / 294\n",
      "Processed frame 55 / 294\n",
      "Processed frame 56 / 294\n",
      "Processed frame 57 / 294\n",
      "Processed frame 58 / 294\n",
      "Processed frame 59 / 294\n",
      "Processed frame 60 / 294\n",
      "Processed frame 61 / 294\n",
      "Processed frame 62 / 294\n",
      "Processed frame 63 / 294\n",
      "Processed frame 64 / 294\n",
      "Processed frame 65 / 294\n",
      "Processed frame 66 / 294\n",
      "Processed frame 67 / 294\n",
      "Processed frame 68 / 294\n",
      "Processed frame 69 / 294\n",
      "Processed frame 70 / 294\n",
      "Processed frame 71 / 294\n",
      "Processed frame 72 / 294\n",
      "Processed frame 73 / 294\n",
      "Processed frame 74 / 294\n",
      "Processed frame 75 / 294\n",
      "Processed frame 76 / 294\n",
      "Processed frame 77 / 294\n",
      "Processed frame 78 / 294\n",
      "Processed frame 79 / 294\n",
      "Processed frame 80 / 294\n",
      "Processed frame 81 / 294\n",
      "Processed frame 82 / 294\n",
      "Processed frame 83 / 294\n",
      "Processed frame 84 / 294\n",
      "Processed frame 85 / 294\n",
      "Processed frame 86 / 294\n",
      "Processed frame 87 / 294\n",
      "Processed frame 88 / 294\n",
      "Processed frame 89 / 294\n",
      "Processed frame 90 / 294\n",
      "Processed frame 91 / 294\n",
      "Processed frame 92 / 294\n",
      "Processed frame 93 / 294\n",
      "Processed frame 94 / 294\n",
      "Processed frame 95 / 294\n",
      "Processed frame 96 / 294\n",
      "Processed frame 97 / 294\n",
      "Processed frame 98 / 294\n",
      "Processed frame 99 / 294\n",
      "Processed frame 100 / 294\n",
      "Processed frame 101 / 294\n",
      "Processed frame 102 / 294\n",
      "Processed frame 103 / 294\n",
      "Processed frame 104 / 294\n",
      "Processed frame 105 / 294\n",
      "Processed frame 106 / 294\n",
      "Processed frame 107 / 294\n",
      "Processed frame 108 / 294\n",
      "Processed frame 109 / 294\n",
      "Processed frame 110 / 294\n",
      "Processed frame 111 / 294\n",
      "Processed frame 112 / 294\n",
      "Processed frame 113 / 294\n",
      "Processed frame 114 / 294\n",
      "Processed frame 115 / 294\n",
      "Processed frame 116 / 294\n",
      "Processed frame 117 / 294\n",
      "Processed frame 118 / 294\n",
      "Processed frame 119 / 294\n",
      "Processed frame 120 / 294\n",
      "Processed frame 121 / 294\n",
      "Processed frame 122 / 294\n",
      "Processed frame 123 / 294\n",
      "Processed frame 124 / 294\n",
      "Processed frame 125 / 294\n",
      "Processed frame 126 / 294\n",
      "Processed frame 127 / 294\n",
      "Processed frame 128 / 294\n",
      "Processed frame 129 / 294\n",
      "Processed frame 130 / 294\n",
      "Processed frame 131 / 294\n",
      "Processed frame 132 / 294\n",
      "Processed frame 133 / 294\n",
      "Processed frame 134 / 294\n",
      "Processed frame 135 / 294\n",
      "Processed frame 136 / 294\n",
      "Processed frame 137 / 294\n",
      "Processed frame 138 / 294\n",
      "Processed frame 139 / 294\n",
      "Processed frame 140 / 294\n",
      "Processed frame 141 / 294\n",
      "Processed frame 142 / 294\n",
      "Processed frame 143 / 294\n",
      "Processed frame 144 / 294\n",
      "Processed frame 145 / 294\n",
      "Processed frame 146 / 294\n",
      "Processed frame 147 / 294\n",
      "Processed frame 148 / 294\n",
      "Processed frame 149 / 294\n",
      "Processed frame 150 / 294\n",
      "Processed frame 151 / 294\n",
      "Processed frame 152 / 294\n",
      "Processed frame 153 / 294\n",
      "Processed frame 154 / 294\n",
      "Processed frame 155 / 294\n",
      "Processed frame 156 / 294\n",
      "Processed frame 157 / 294\n",
      "Processed frame 158 / 294\n",
      "Processed frame 159 / 294\n",
      "Processed frame 160 / 294\n",
      "Processed frame 161 / 294\n",
      "Processed frame 162 / 294\n",
      "Processed frame 163 / 294\n",
      "Processed frame 164 / 294\n",
      "Processed frame 165 / 294\n",
      "Processed frame 166 / 294\n",
      "Processed frame 167 / 294\n",
      "Processed frame 168 / 294\n",
      "Processed frame 169 / 294\n",
      "Processed frame 170 / 294\n",
      "Processed frame 171 / 294\n",
      "Processed frame 172 / 294\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://detect.roboflow.com/motorcycle-detection-ctu3w/2?api_key=lNRNQAqP9F0FHx3Bokha&name=YOUR_IMAGE.jpg&overlap=30&confidence=50&stroke=1&labels=false&format=json",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 42\u001b[0m result_motorcycle \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_motorcycle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     43\u001b[0m predictions_motorcycle \u001b[38;5;241m=\u001b[39m result_motorcycle[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     45\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\roboflow\\models\\object_detection.py:241\u001b[0m, in \u001b[0;36mObjectDetectionModel.predict\u001b[1;34m(self, image_path, hosted, format, classes, overlap, confidence, stroke, labels)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# POST to the API\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url)\n\u001b[1;32m--> 241\u001b[0m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Return a prediction group if JSON data\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dongn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://detect.roboflow.com/motorcycle-detection-ctu3w/2?api_key=lNRNQAqP9F0FHx3Bokha&name=YOUR_IMAGE.jpg&overlap=30&confidence=50&stroke=1&labels=false&format=json"
     ]
    }
   ],
   "source": [
    "def get_unique_filename(file_path):\n",
    "    base, extension = os.path.splitext(file_path)\n",
    "    counter = 1\n",
    "    new_file_path = file_path\n",
    "    while os.path.exists(new_file_path):\n",
    "        new_file_path = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "    return new_file_path\n",
    "\n",
    "# Paths\n",
    "video_path = r\"Sample\\Video\\market_vn.mp4\"\n",
    "output_path = r\"Predict\\Video\\result.mp4\"\n",
    "temp_image_base = r\"D:\\Projects\\Helmet detection\\Predict\\Temp_frame\\temp_motorcycle.jpg\"\n",
    "\n",
    "# Check whether directory exists\n",
    "os.makedirs(os.path.dirname(temp_image_base), exist_ok=True)\n",
    "\n",
    "# Video setup\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Load Roboflow models\n",
    "rf_motorcycle = Roboflow(api_key=\"lNRNQAqP9F0FHx3Bokha\")\n",
    "model_motorcycle = rf_motorcycle.workspace(\"vens-shell\").project(\"motorcycle-detection-ctu3w\").version(2).model\n",
    "\n",
    "rf_helmet = Roboflow(api_key=\"AlBM3nHUZMJlOEAokjuW\")\n",
    "model_helmet = rf_helmet.workspace().project(\"helmet-and-nonhelmet-detection\").version(1).model\n",
    "\n",
    "# Main loop\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    result_motorcycle = model_motorcycle.predict(frame, confidence=50, overlap=30).json()\n",
    "    predictions_motorcycle = result_motorcycle[\"predictions\"]\n",
    "\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    box_thickness = max(1, int(min(image_width, image_height) * 0.009))\n",
    "    font_size = max(10, int(min(image_width, image_height) * 0.006))\n",
    "\n",
    "    all_predictions_helmet = []\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for motorcycle in predictions_motorcycle:\n",
    "        x, y, w, h = motorcycle['x'], motorcycle['y'], motorcycle['width'], motorcycle['height']\n",
    "        moto_x0, moto_y0 = x - w / 2, y - h / 2\n",
    "        moto_x1, moto_y1 = x + w / 2, y + h / 2\n",
    "\n",
    "        motorcycle_image = image.crop((moto_x0, moto_y0, moto_x1, moto_y1))\n",
    "        motorcycle_array = np.array(motorcycle_image)\n",
    "        result_helmet = model_helmet.predict(motorcycle_array, confidence=60, overlap=30, labels=True)\n",
    "        all_predictions_helmet.extend(result_helmet.predictions)\n",
    "\n",
    "        for prediction in predictions_helmet:\n",
    "            px, py, pw, ph = prediction['x'] + moto_x0, prediction['y'] + moto_y0, prediction['width'], prediction['height']\n",
    "            x0, y0 = px - pw / 2, py - ph / 2\n",
    "            x1, y1 = px + pw / 2, py + ph / 2\n",
    "            label = f\"({prediction['confidence'] * 100:.1f}%)\"\n",
    "\n",
    "            label_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "            label_w = label_bbox[2] - label_bbox[0] + 10\n",
    "            label_h = label_bbox[3] - label_bbox[1] + 5\n",
    "\n",
    "            color = \"green\" if prediction['class'] == \"Helmet\" else \"red\"\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=color, width=box_thickness)\n",
    "            draw.rectangle([x0, y0 - label_h, x0 + label_w, y0], fill=color)\n",
    "            draw.text((x0 + 5, y0 - label_h), label, fill=\"black\", font=font)\n",
    "\n",
    "    # Draw FPS\n",
    "    elapsed_time = time.time() - start_time\n",
    "    current_fps = 1.0 / elapsed_time if elapsed_time > 0 else 0\n",
    "    fps_text = f\"{current_fps:.2f} FPS\"\n",
    "    processed_frame = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Count helmets and non-helmets\n",
    "    helmet_count = sum(1 for pred in all_predictions_helmet if pred['class'] == \"Helmet\")\n",
    "    nonhelmet_count = sum(1 for pred in all_predictions_helmet if pred['class'] == \"Nonhelmet\")\n",
    "\n",
    "    # Format for text\n",
    "    fps_text = f\"{current_fps:.2f} FPS\"\n",
    "    timestamp_text = f\"Time: {cap.get(cv2.CAP_PROP_POS_MSEC) / 1000:.1f}s\"\n",
    "    helmet_text = f\"Helmet: {helmet_count}\"\n",
    "    nonhelmet_text = f\"Nonhelmet: {nonhelmet_count}\"\n",
    "\n",
    "    # Print text on screen\n",
    "    cv2.putText(processed_frame, fps_text, (frame_width - 180, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.putText(processed_frame, timestamp_text, (frame_width - 180, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.putText(processed_frame, helmet_text, (10, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.putText(processed_frame, nonhelmet_text, (10, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    out.write(processed_frame)\n",
    "\n",
    "    print(f\"Processed frame {int(cap.get(cv2.CAP_PROP_POS_FRAMES))} / {int(cap.get(cv2.CAP_PROP_FRAME_COUNT))}\")\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
